{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:242: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "c:\\Users\\azhar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:286: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "c:\\Users\\azhar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:319: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nni\n",
    "from nni.nas.nn.pytorch import LayerChoice, ModelSpace, MutableDropout, MutableLinear\n",
    "import nni.nas.strategy as strategy\n",
    "from nni.nas.strategy.middleware import Filter, Chain\n",
    "from nni.nas.profiler.pytorch.flops import NumParamsProfiler\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "from nni.nas.experiment import NasExperiment\n",
    "import time\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Space with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelSpace(ModelSpace):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = LayerChoice([\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.Conv2d(1,32,5,1,1),],label = \"conv1\")\n",
    "        \n",
    "        self.conv2 = LayerChoice([\n",
    "            nn.Conv2d(32, 64,3,1),\n",
    "            nn.Conv2d(32, 64,5,1,1),\n",
    "            \n",
    "        ], label='conv2')\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = MutableDropout(nni.choice('dropout', [0.25, 0.5, 0.75]))  \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nni.choice('feature', [64, 128, 256])\n",
    "        self.fc1 = MutableLinear(9216, feature)\n",
    "        self.fc2 = MutableLinear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_space = MyModelSpace()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get memory of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    num_buffers = sum(b.numel() for b in model.buffers())\n",
    "    total_size = num_params + num_buffers\n",
    "    return total_size * 4 / (1024 ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate a model and report performance metric to NNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    transf = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the pixel values\n",
    "])\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transf, download=True)\n",
    "    test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transf   , download=True)\n",
    "\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)        \n",
    "\n",
    "    for epoch in range(3):\n",
    "        \n",
    "        dict={\"default\":0.0,\"accuracy\":0.0,\"latency\":0.0,\"memory\":0.0}\n",
    "        \n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        tim1=time.time()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        \n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        \n",
    "        time2 = time.time()-tim1\n",
    "        mem = get_model_size(model)\n",
    "        met = ((accuracy/100)-((time2-1)/(2-1))-((mem-2)/(10-2)))*100\n",
    "        dict['default']=float(met)\n",
    "        dict['accuracy']=accuracy\n",
    "        dict['latency']=time2\n",
    "        dict[\"memory\"]=mem\n",
    "        \n",
    "        nni.report_intermediate_result(dict)\n",
    "\n",
    "    \n",
    "    nni.report_final_result(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the evaluator of NNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = FunctionalEvaluator(evaluate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining  different stratergies to evalaute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-05 18:06:25] \u001b[32mUsing random seed 2111768997\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "search_strategy1 = strategy.Random() \n",
    "search_strategy2 = strategy.RegularizedEvolution()  \n",
    "search_strategy3 = strategy.TPE()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Experiment for different stratergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-05 18:06:25] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing execution engine based on training service. Trial concurrency is set to 1.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing simplified model format.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing local training service.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[33mWARNING: GPU found but will not be used. Please set `experiment.config.trial_gpu_number` to the number of GPUs you want to use for each trial.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing execution engine based on training service. Trial concurrency is set to 1.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing simplified model format.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing local training service.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[33mWARNING: GPU found but will not be used. Please set `experiment.config.trial_gpu_number` to the number of GPUs you want to use for each trial.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing execution engine based on training service. Trial concurrency is set to 1.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing simplified model format.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[32mUsing local training service.\u001b[0m\n",
      "[2024-05-05 18:06:25] \u001b[33mWARNING: GPU found but will not be used. Please set `experiment.config.trial_gpu_number` to the number of GPUs you want to use for each trial.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment1 = NasExperiment(model_space, evaluator, search_strategy1)\n",
    "experiment2 = NasExperiment(model_space, evaluator, search_strategy2)\n",
    "experiment3 = NasExperiment(model_space, evaluator, search_strategy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running experiments on differnt ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-05 18:06:26] \u001b[32mCreating experiment, Experiment ID: \u001b[36mr9iv4tkb\u001b[0m\n",
      "[2024-05-05 18:06:26] \u001b[32mStarting web server...\u001b[0m\n",
      "[2024-05-05 18:06:28] \u001b[32mSetting up...\u001b[0m\n",
      "[2024-05-05 18:06:29] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.55.27:8085 http://169.254.97.166:8085 http://192.168.56.1:8085 http://169.254.83.81:8085 http://169.254.82.251:8085 http://169.254.92.2:8085 http://172.31.25.119:8085 http://169.254.253.36:8085 http://169.254.191.241:8085 http://127.0.0.1:8085\u001b[0m\n",
      "[2024-05-05 18:06:29] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "[2024-05-05 18:06:29] \u001b[32mCheckpoint saved to C:\\Users\\azhar\\nni-experiments\\r9iv4tkb\\checkpoint.\u001b[0m\n",
      "[2024-05-05 18:06:29] \u001b[32mExperiment initialized successfully. Starting exploration strategy...\u001b[0m\n",
      "[2024-05-05 18:16:13] \u001b[32mWaiting for models submitted to engine to finish...\u001b[0m\n",
      "[2024-05-05 18:17:16] \u001b[32mExperiment is completed.\u001b[0m\n",
      "[2024-05-05 18:17:16] \u001b[32mSearch process is done. You can put an `time.sleep(FOREVER)` here to block the process if you want to continue viewing the experiment.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment1.run(port=8085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-05 18:17:18] \u001b[32mCreating experiment, Experiment ID: \u001b[36mk4gef6vw\u001b[0m\n",
      "[2024-05-05 18:17:18] \u001b[32mStarting web server...\u001b[0m\n",
      "[2024-05-05 18:17:19] \u001b[32mSetting up...\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.55.27:8086 http://169.254.97.166:8086 http://192.168.56.1:8086 http://169.254.83.81:8086 http://169.254.82.251:8086 http://169.254.92.2:8086 http://172.31.25.119:8086 http://169.254.253.36:8086 http://169.254.191.241:8086 http://127.0.0.1:8086\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32mCheckpoint saved to C:\\Users\\azhar\\nni-experiments\\k4gef6vw\\checkpoint.\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32mExperiment initialized successfully. Starting exploration strategy...\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32mSpawning the initial population. 100 individuals to go.\u001b[0m\n",
      "[2024-05-05 18:17:20] \u001b[32m[Individual    1] Random: {'conv1': 0, 'conv2': 1, 'dropout': 0.5, 'feature': 128}\u001b[0m\n",
      "[2024-05-05 18:18:25] \u001b[32m[Metric] -65.380544 Sample: {'conv1': 0, 'conv2': 1, 'dropout': 0.5, 'feature': 128}\u001b[0m\n",
      "[2024-05-05 18:18:26] \u001b[32m[Individual    2] Random: {'conv1': 1, 'conv2': 0, 'dropout': 0.75, 'feature': 64}\u001b[0m\n",
      "[2024-05-05 18:19:32] \u001b[32m[Metric] -1.732954 Sample: {'conv1': 1, 'conv2': 0, 'dropout': 0.75, 'feature': 64}\u001b[0m\n",
      "[2024-05-05 18:19:33] \u001b[32m[Individual    3] Random: {'conv1': 1, 'conv2': 1, 'dropout': 0.75, 'feature': 64}\u001b[0m\n",
      "[2024-05-05 18:20:35] \u001b[32m[Metric] 5.850755 Sample: {'conv1': 1, 'conv2': 1, 'dropout': 0.75, 'feature': 64}\u001b[0m\n",
      "[2024-05-05 18:20:35] \u001b[32m[Individual    4] Random: {'conv1': 1, 'conv2': 0, 'dropout': 0.25, 'feature': 256}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment2.run(port=8086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-05 17:26:17] \u001b[32mCreating experiment, Experiment ID: \u001b[36mm1xv6sn9\u001b[0m\n",
      "[2024-05-05 17:26:17] \u001b[32mStarting web server...\u001b[0m\n",
      "[2024-05-05 17:26:18] \u001b[32mSetting up...\u001b[0m\n",
      "[2024-05-05 17:26:19] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.55.27:8087 http://169.254.97.166:8087 http://192.168.56.1:8087 http://169.254.83.81:8087 http://169.254.82.251:8087 http://169.254.92.2:8087 http://172.31.25.119:8087 http://169.254.253.36:8087 http://169.254.191.241:8087 http://127.0.0.1:8087\u001b[0m\n",
      "[2024-05-05 17:26:19] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "[2024-05-05 17:26:19] \u001b[32mCheckpoint saved to C:\\Users\\azhar\\nni-experiments\\m1xv6sn9\\checkpoint.\u001b[0m\n",
      "[2024-05-05 17:26:19] \u001b[32mExperiment initialized successfully. Starting exploration strategy...\u001b[0m\n",
      "[2024-05-05 17:38:48] \u001b[32mTuning algorithm generated duplicate parameter: {('conv1',): 0, ('conv2',): 1, ('dropout',): 2, ('feature',): 1}\u001b[0m\n",
      "[2024-05-05 17:38:48] \u001b[32mUse grid search for deduplication.\u001b[0m\n",
      "[2024-05-05 17:38:48] \u001b[32mGrid initialized, size: (2×2×3×3) = 36\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment3.run(port=8087)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
